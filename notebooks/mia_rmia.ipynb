{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3add812",
   "metadata": {},
   "source": [
    "# Membership Inference using Robust Membership Inference Attack (RMIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29916c6d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3227c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from privacy_and_grokking.path_keeper import get_path_keeper\n",
    "from privacy_and_grokking.utils import get_device\n",
    "from privacy_and_grokking.datasets import MNIST\n",
    "from privacy_and_grokking.models import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "344f5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = get_path_keeper()\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896425b",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e9025e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(model, inputs, labels, device='cpu'):\n",
    "    model.eval()\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs)\n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "        true_class_log_probs = log_probs.gather(1, labels.view(-1, 1)).squeeze()\n",
    "        \n",
    "    return true_class_log_probs\n",
    "\n",
    "def rmia_score(target_model, ref_model, target_x, target_y, population_data, population_labels, device='cpu'):\n",
    "    \"\"\"\n",
    "    Implements the RMIA scoring function.\n",
    "    \n",
    "    Args:\n",
    "        target_model: The model under attack.\n",
    "        ref_model: The reference model (independent).\n",
    "        target_x: The specific data point to test (single sample).\n",
    "        target_y: The label of the target data point.\n",
    "        population_data: A batch of non-member data samples (z).\n",
    "        population_labels: Labels for the population data.\n",
    "    \n",
    "    Returns:\n",
    "        float: The RMIA score (0.0 to 1.0). Higher score = higher probability of membership.\n",
    "    \"\"\"\n",
    "    # 1. Compute Log-Likelihoods for the Target Sample (x)\n",
    "    # P(x | theta_target)\n",
    "    ll_target_x = compute_log_likelihood(target_model, target_x.unsqueeze(0), target_y.unsqueeze(0), device)\n",
    "    # P(x | theta_ref)\n",
    "    ll_ref_x = compute_log_likelihood(ref_model, target_x.unsqueeze(0), target_y.unsqueeze(0), device)\n",
    "    \n",
    "    # Ratio for x: P(x|Target) / P(x|Ref) -> Log difference\n",
    "    ratio_x = ll_target_x - ll_ref_x\n",
    "    \n",
    "    # 2. Compute Log-Likelihoods for Population Data (z)\n",
    "    # P(z | theta_target)\n",
    "    ll_target_z = compute_log_likelihood(target_model, population_data, population_labels, device)\n",
    "    # P(z | theta_ref)\n",
    "    ll_ref_z = compute_log_likelihood(ref_model, population_data, population_labels, device)\n",
    "    \n",
    "    # Ratio for z: P(z|Target) / P(z|Ref) -> Log difference\n",
    "    ratio_z = ll_target_z - ll_ref_z\n",
    "    \n",
    "    # 3. Pairwise Comparison (The RMIA Test)\n",
    "    # We want to count how many times Ratio(x) > Ratio(z)\n",
    "    # Because we are in log space: (ll_target_x - ll_ref_x) > (ll_target_z - ll_ref_z)\n",
    "    \n",
    "    # This effectively computes: P( LR(x, z) > 1 ) over all z\n",
    "    pairwise_comparisons = (ratio_x > ratio_z).float()\n",
    "    \n",
    "    score = pairwise_comparisons.mean().item()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 10000\n"
     ]
    }
   ],
   "source": [
    "train, test = MNIST(size=\"small\", canary=\"gaussian_noise\")()\n",
    "print(len(train), len(test))\n",
    "\n",
    "population_x, population_y = [], []\n",
    "for x, y in test:\n",
    "    population_x.append(x)\n",
    "    population_y.append(y)\n",
    "    if len(population_x) == 1000:\n",
    "        break\n",
    "population_x, population_y = torch.stack(population_x), torch.tensor(population_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3cf491f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.set_params({\"run_id\": \"v1.3.0\", \"model\": \"MLP_GROK_CAN_NOISE_V1\", \"step\": 100_000})\n",
    "\n",
    "target_model = MLP()\n",
    "target_model.load_state_dict(torch.load(pk.MODEL_TORCH, weights_only=True, map_location=device))\n",
    "target_model.to(device)\n",
    "\n",
    "pk.set_params({\"run_id\": \"v1.3.0\", \"model\": \"MLP_V1\", \"step\": 100_000})\n",
    "reference_model = MLP()\n",
    "reference_model.load_state_dict(torch.load(pk.MODEL_TORCH, weights_only=True, map_location=device))\n",
    "reference_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d87cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5465)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for target_x, target_y in test:\n",
    "    target_y = torch.tensor(target_y)\n",
    "    score = rmia_score(target_model, reference_model, target_x, target_y, population_x, population_y, device)\n",
    "    scores.append(score)\n",
    "scores = torch.tensor(scores)\n",
    "(scores > 0.5).sum() / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d3cbe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9990)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for target_x, target_y in train:\n",
    "    score = rmia_score(target_model, reference_model, target_x, target_y, population_x, population_y, device)\n",
    "    scores.append(score)\n",
    "scores = torch.tensor(scores)\n",
    "(scores > 0.5).sum() / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72128e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy-and-grokking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
